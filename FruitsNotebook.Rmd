---
title: "Fresh and Stale Fruits"
output: html_notebook
---

# Data Wrangling

First let's import some needed libraries. Tidyverse is needed for 
```{r}
# Load the libraries needed
library(keras)
library(tidyverse)
library(imager)
library(caret)

list.files(path = "../input")

dir = '../input/fresh-and-stale-images-of-fruits-and-vegetables/'

```
There is no test/training partition given for the dataset so I went through every image directory and combined all the images into a dataframe which was then split into a training and testing dataset in the following steps.

## Printing Sample

Just to make sure that loading in the images works we plot a sample image from the fresh-apple directory.
```{r}
# sets up path to fresh apples and sees if an image from it works
fresh_apple_dir <- '../input/fresh-and-stale-images-of-fruits-and-vegetables/fresh_apple/'
fresh_apple <- list.files(fresh_apple_dir)

test_image <- load.image(paste(fresh_apple_dir, fresh_apple[1], sep = ''))
plot(test_image)
```
## Grayscale

Next let's make the image grayscale to make it easier to work with and to reduce computation time.
```{r}
test_image_gray <- grayscale(test_image)
plot(test_image_gray)
```
## Resizing

A thing to note is that all these files can potentially be inconsistent in terms of size so the images will need to be regularized
```{r}
load.image(paste(fresh_apple_dir, fresh_apple[1], sep = ''))
load.image(paste(fresh_apple_dir, fresh_apple[56], sep = ''))
```
Let's reduce all the images to, say, $20 \times 20$ to make sizing consistent and reduce computation time. This is especially needed since we are working with rgb images
```{r}
new_dim <- 20
resized_test_image <- resize(test_image, new_dim, new_dim)
plot(resized_test_image)
```
## Putting it all together

### Obtaining Names of all the Sub-Folders
Let's obtain the different categories of this dataset so we don't have to individually do each category
```{r}
categories <- list.files("../input/fresh-and-stale-images-of-fruits-and-vegetables/")
print(categories)
```

### Dataframe creation
We have 6 fresh labels, the text file that has all the labels, and then the 6 stale labels. We can take out the text file and then create a massive dataframe with the pixel values adding the and resizing. A function will be made to convert CMYK images to RGB images since those are in the dataset provided.
```{r}
cmyk_to_rgb <- function(v) {
  ret_v <- vector(length = 1200)
  for (i in 1:400) {
    ret_v[i] <- (1 - v[i]) * (1 - v[1200 + i])
    ret_v[i + 400] <- (1 - v[400 + i]) * (1 - v[1200 + i])
    ret_v[i + 800] <- (1 - v[800 + i]) * (1 - v[1200 + i])
  }
  return(ret_v)
}
```

```{r} 
category <- categories[-7]
total <- NULL
start_time <- Sys.time()
for (i in 1:length(category)) {
  path <- paste(dir, category[i], '/', sep = '')
  image_names <- list.files(path)
  len <- length(image_names)
  out <- data.frame(matrix(NA, nrow = len, ncol = new_dim * new_dim * 3))
  for (j in 1:len) {
    imag <- load.image(paste(path, image_names[j], sep = ''))
    imag <- resize(imag, new_dim, new_dim) # TODO: figure out how to turn cmyk images to rgb
    imag <- as.vector(imag)
    if (length(imag) > 1200) {
      imag <- cmyk_to_rgb(imag)
    }
    out[j,] <- t(imag)
  }
  # adds FSF = Fresh/Stale Food, FS = Fresh/Stale, Food = Type of Fruit
  out <- cbind(FSF = category[i], FS = substring(category[i], 1, 5), 
               Food = substring(category[i], 7), out) 
  total <- rbind(total, out)
}
print(Sys.time() - start_time)
```
The way this dataframe is set up whether it's fresh or stale will be written in the first state column. We can now split the dataset into training and testing data
```{r}
set.seed(4761)
indices <- sort(sample(nrow(total), nrow(total) * 0.75))
train_x <- total[indices, 4:ncol(total)]
test_x <- total[-indices, 4:ncol(total)]
train_y_FSF <- total[indices, 1]
test_y_FSF <- total[-indices, 1]
train_y_FS <- total[indices, 2]
test_y_FS <- total[-indices, 2]
train_y_Food <- total[indices, 3]
test_y_Food <- total[-indices, 3]
```

# KNN-Classification

Now let's create a few different models to test how well each can identify each of the different traits. I predict that there will be a hard time with the fresh/stale identification since there is so much variance within the categories of fresh and stale and that there will be more success with the state of the food + what kind of food it is, even though that'd increase the amount of categories to 12.

## Complete Entry

First lets try out different k values for when the different categories are the type of fruit in addition to whether it's fresh or stale.
```{r State+Type of Food}
set.seed(4761)
k <- data.frame(k = seq(from = 1, to = 21, by = 1))
train_control <- trainControl(method = "cv", number = 5)
selecting_k <- train(x = train_x, y = train_y_FSF, method = "knn", tuneGrid = k, trControl = train_control)
k_accuracies <- selecting_k$results %>% select(k, Accuracy)
ggplot(k_accuracies, aes(x = k, y = Accuracy)) + geom_point() + geom_line()
```

It can be seen that a $k = 1$ is ideal. There was no up-sampling methods employed so there is no risk of over-sampling. Lets see how the model works with the test data.
```{r}
set.seed(4761)
chosen_k <- data.frame(k = 1)
start_time <- Sys.time()
knn_model <- train(x = train_x, train_y_FSF, method = "knn", tuneGrid = chosen_k)
print(Sys.time() - start_time)
predicted_y <- predict(knn_model, test_x)
results <- confusionMatrix(data = predicted_y, reference = as.factor(test_y_FSF))
results
```

## Fresh/Stale Classifier
Now let's do the same but with just the knowledge that the fruit is fresh or stale.
```{r State}
set.seed(4761)
k <- data.frame(k = seq(from = 1, to = 21, by = 1))
train_control <- trainControl(method = "cv", number = 5)
start_time <- Sys.time()
selecting_k <- train(x = train_x, y = train_y_FS, method = "knn", tuneGrid = k, trControl = train_control)
print(Sys.time() - start_time)
k_accuracies <- selecting_k$results %>% select(k, Accuracy)
ggplot(k_accuracies, aes(x = k, y = Accuracy)) + geom_point() + geom_line()
```

It can be seen that a $k = 3$ is ideal.
```{r}
set.seed(4761)
chosen_k <- data.frame(k = 3)
start_time <- Sys.time()
knn_model <- train(x = train_x, train_y_FS, method = "knn", tuneGrid = chosen_k)
print(Sys.time() - start_time)
predicted_y <- predict(knn_model, test_x)
results <- confusionMatrix(data = predicted_y, reference = as.factor(test_y_FS))
results
```

## Fruit Identification

Finally let's see how accurately we can tune a model for identification of the type of fruit.
```{r Type of Food}
set.seed(4761)
k <- data.frame(k = seq(from = 1, to = 21, by = 1))
train_control <- trainControl(method = "cv", number = 5)
start_time <- Sys.time()
selecting_k <- train(x = train_x, y = train_y_Food, method = "knn", tuneGrid = k, trControl = train_control)
print(Sys.time() - start_time)
k_accuracies <- selecting_k$results %>% select(k, Accuracy)
ggplot(k_accuracies, aes(x = k, y = Accuracy)) + geom_point() + geom_line()
```


It can be seen that a $k = 1$ is ideal.
```{r}
set.seed(4761)
chosen_k <- data.frame(k = 1)
start_time <- Sys.time()
knn_model <- train(x = train_x, train_y_Food, method = "knn", tuneGrid = chosen_k)
print(Sys.time() - start_time)
predicted_y <- predict(knn_model, test_x)
results <- confusionMatrix(data = predicted_y, reference = as.factor(test_y_Food))
results
```